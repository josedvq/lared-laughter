{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from models.models import MLPModel, ResNetBigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lared_laughter.constants import dataset_path, audioset_data_path\n",
    "from dataset import SwitchBoardLaughterDataset\n",
    "from audio_utils import featurize_mfcc, featurize_melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class System(pl.LightningModule):\n",
    "    def __init__(self, model_name, model_hparams={}, optimizer_name='adam', optimizer_hparams={}):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = {\n",
    "            'mlp': MLPModel(),\n",
    "            'resnet': ResNetBigger(linear_layer_size=64, filter_sizes=[64,32,16,16])\n",
    "        }[model_name]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        X, Y = batch\n",
    "\n",
    "        output = self.model(X).squeeze()\n",
    "        loss = F.binary_cross_entropy_with_logits(output, Y.float())\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=.001)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, Y = batch\n",
    "\n",
    "        output = self.model(X).squeeze()\n",
    "        val_loss = F.binary_cross_entropy_with_logits(output, Y.float())\n",
    "        self.log('val_loss', val_loss)\n",
    "\n",
    "        return (output, Y.squeeze())\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        all_outputs = torch.cat([o[0] for o in validation_step_outputs]).cpu()\n",
    "        all_labels = torch.cat([o[1] for o in validation_step_outputs]).cpu()\n",
    "\n",
    "        try:\n",
    "            val_auc = roc_auc_score(all_labels, all_outputs)\n",
    "            self.log('val_auc', val_auc)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, Y = batch\n",
    "\n",
    "        output = self.model(X).squeeze()\n",
    "\n",
    "        return (output, Y.squeeze())\n",
    "\n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        all_outputs = torch.cat([o[0] for o in test_step_outputs]).cpu()\n",
    "        all_labels = torch.cat([o[1] for o in test_step_outputs]).cpu()\n",
    "\n",
    "        self.test_results = {'proba': all_outputs, 'labels': all_labels}\n",
    "        try:\n",
    "            test_auc = roc_auc_score(all_labels, all_outputs)\n",
    "            self.test_results['auc'] = test_auc\n",
    "            self.log('test_auc', test_auc)\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fold(train_ds, test_ds, model_name='resnet', trainer_params={}):\n",
    "    # data loaders\n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_ds, batch_size=100, shuffle=True, num_workers=10,\n",
    "        collate_fn=None)\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=100, shuffle=False, num_workers=10,\n",
    "        collate_fn=None)\n",
    "\n",
    "    system = System(model_name)\n",
    "    trainer_fn = partial(pl.Trainer, **trainer_params)\n",
    "    trainer = trainer_fn(\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")] + trainer_params.get('callbacks', []),\n",
    "        accelerator='gpu',\n",
    "        log_every_n_steps=1,\n",
    "        max_epochs=-1)\n",
    "    trainer.fit(system, data_loader_train, data_loader_val)\n",
    "\n",
    "    trainer.test(system, data_loader_val)\n",
    "    return system.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(outputs, labels, type='binary'):\n",
    "    if type == 'binary':\n",
    "        proba = torch.sigmoid(outputs)\n",
    "        pred = (proba > 0.5)\n",
    "\n",
    "        correct = pred.eq(outputs.bool()).sum().item()\n",
    "        return {\n",
    "            'auc': roc_auc_score(labels, proba),\n",
    "            'correct': correct\n",
    "        }\n",
    "    elif type == 'regression':\n",
    "        return {\n",
    "            'mse': torch.nn.functional.mse_loss(outputs, labels, reduction='mean'),\n",
    "            'l1': torch.nn.functional.l1_loss(outputs, labels, reduction='mean')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_run(dataset, model_name, metrics_name='binary'):\n",
    "    \n",
    "    seed = 22\n",
    "    cv_splits = KFold(n_splits=2, random_state=seed, shuffle=True).split(range(len(ds)))\n",
    "\n",
    "    outputs = torch.empty((len(ds),))\n",
    "    for f, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        # create datasets    \n",
    "        train_ds = Subset(dataset, train_idx)\n",
    "        test_ds = Subset(dataset, test_idx)\n",
    "\n",
    "        fold_outputs = do_fold(train_ds, test_ds, model_name)\n",
    "        outputs[test_idx] = fold_outputs['proba'].cpu()\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    labels = torch.Tensor(ds.get_all_labels())\n",
    "    run_metrics = get_metrics(outputs, labels, metrics_name)\n",
    "    return outputs, run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loading\n",
    "audioset_examples = pd.read_csv('./data/audioset/examples.csv')\n",
    "audioset_audios = pickle.load(open(os.path.join(audioset_data_path, 'audioset_audios.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: 19354, audios: 15947, not found: 3407\n",
      "df: 15947, audios: 15947, not found: 3407\n"
     ]
    }
   ],
   "source": [
    "asds = SwitchBoardLaughterDataset(\n",
    "    df=audioset_examples,\n",
    "    audios=audioset_audios,\n",
    "    feature_fn=partial(featurize_melspec, hop_length=186),\n",
    "    sr=8000,\n",
    "    subsample_length=1,\n",
    "    id_column='yt_id',\n",
    "    label_column='laughter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 44, 128)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asds[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the audioset model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seeds\n",
    "pl.utilities.seed.seed_everything(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves top-K checkpoints based on \"val_loss\" metric\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    dirpath=\"./pretrained_audioset/\",\n",
    "    filename=\"audioset-{epoch:02d}-{val_loss:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000018vscode-remote?line=0'>1</a>\u001b[0m train_idx, test_idx \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(ShuffleSplit(n_splits\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, test_size\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m22\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(ds)))))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000018vscode-remote?line=1'>2</a>\u001b[0m train_ds \u001b[39m=\u001b[39m Subset(ds, train_idx)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000018vscode-remote?line=2'>3</a>\u001b[0m test_ds \u001b[39m=\u001b[39m Subset(ds, test_idx)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "train_idx, test_idx = next(iter(ShuffleSplit(n_splits=1, test_size=0.15, random_state=22).split(range(len(ds)))))\n",
    "train_ds = Subset(ds, train_idx)\n",
    "test_ds = Subset(ds, test_idx)\n",
    "fold_outputs = do_fold(train_ds, test_ds, 'resnet',\n",
    "    trainer_params={'callbacks': [checkpoint_callback]})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
