{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from models.models import MLPModel, ResNetBigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lared_laughter.constants import dataset_path, audioset_data_path\n",
    "from dataset import SwitchBoardLaughterDataset\n",
    "from audio_utils import featurize_mfcc, featurize_melspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class System(pl.LightningModule):\n",
    "    def __init__(self, model_name, model_hparams={}, optimizer_name='adam', optimizer_hparams={}):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = {\n",
    "            'mlp': MLPModel(),\n",
    "            'resnet': ResNetBigger(linear_layer_size=64, filter_sizes=[64,32,16,16])\n",
    "        }[model_name]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        X, Y = batch\n",
    "\n",
    "        output = self.model(X).squeeze()\n",
    "        loss = F.binary_cross_entropy_with_logits(output, Y.float())\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=.001)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, Y = batch\n",
    "\n",
    "        output = self.model(X).squeeze()\n",
    "        val_loss = F.binary_cross_entropy_with_logits(output, Y.float())\n",
    "        self.log('val_loss', val_loss)\n",
    "\n",
    "        return (output, Y.squeeze())\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        all_outputs = torch.cat([o[0] for o in validation_step_outputs]).cpu()\n",
    "        all_labels = torch.cat([o[1] for o in validation_step_outputs]).cpu()\n",
    "\n",
    "        try:\n",
    "            val_auc = roc_auc_score(all_labels, all_outputs)\n",
    "            self.log('val_auc', val_auc)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, Y = batch\n",
    "\n",
    "        output = self.model(X).squeeze()\n",
    "\n",
    "        return (output, Y.squeeze())\n",
    "\n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        all_outputs = torch.cat([o[0] for o in test_step_outputs]).cpu()\n",
    "        all_labels = torch.cat([o[1] for o in test_step_outputs]).cpu()\n",
    "\n",
    "        self.test_results = {'proba': all_outputs, 'labels': all_labels}\n",
    "        try:\n",
    "            test_auc = roc_auc_score(all_labels, all_outputs)\n",
    "            self.test_results['auc'] = test_auc\n",
    "            self.log('test_auc', test_auc)\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fold(train_ds, test_ds, model_name='resnet', trainer_params={}):\n",
    "    # data loaders\n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_ds, batch_size=100, shuffle=True, num_workers=10,\n",
    "        collate_fn=None)\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=100, shuffle=False, num_workers=10,\n",
    "        collate_fn=None)\n",
    "\n",
    "    system = System(model_name)\n",
    "    trainer_fn = partial(pl.Trainer, **trainer_params)\n",
    "    trainer = trainer_fn(\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")] + trainer_params.get('callbacks', []),\n",
    "        accelerator='gpu',\n",
    "        log_every_n_steps=1,\n",
    "        max_epochs=-1)\n",
    "    trainer.fit(system, data_loader_train, data_loader_val)\n",
    "\n",
    "    trainer.test(system, data_loader_val)\n",
    "    return system.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(outputs, labels, type='binary'):\n",
    "    if type == 'binary':\n",
    "        proba = torch.sigmoid(outputs)\n",
    "        pred = (proba > 0.5)\n",
    "\n",
    "        correct = pred.eq(outputs.bool()).sum().item()\n",
    "        return {\n",
    "            'auc': roc_auc_score(labels, proba),\n",
    "            'correct': correct\n",
    "        }\n",
    "    elif type == 'regression':\n",
    "        return {\n",
    "            'mse': torch.nn.functional.mse_loss(outputs, labels, reduction='mean'),\n",
    "            'l1': torch.nn.functional.l1_loss(outputs, labels, reduction='mean')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_run(dataset, model_name, metrics_name='binary'):\n",
    "    \n",
    "    seed = 22\n",
    "    cv_splits = KFold(n_splits=2, random_state=seed, shuffle=True).split(range(len(ds)))\n",
    "\n",
    "    outputs = torch.empty((len(ds),))\n",
    "    for f, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        # create datasets    \n",
    "        train_ds = Subset(dataset, train_idx)\n",
    "        test_ds = Subset(dataset, test_idx)\n",
    "\n",
    "        fold_outputs = do_fold(train_ds, test_ds, model_name)\n",
    "        outputs[test_idx] = fold_outputs['proba'].cpu()\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    labels = torch.Tensor(ds.get_all_labels())\n",
    "    run_metrics = get_metrics(outputs, labels, metrics_name)\n",
    "    return outputs, run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loading\n",
    "audioset_examples = pd.read_csv('./data/audioset/examples.csv')\n",
    "audioset_audios = pickle.load(open(os.path.join(audioset_data_path, 'audioset_audios.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: 19354, audios: 15947, not found: 3407\n",
      "df: 15947, audios: 15947, not found: 3407\n"
     ]
    }
   ],
   "source": [
    "asds = SwitchBoardLaughterDataset(\n",
    "    df=audioset_examples,\n",
    "    audios=audioset_audios,\n",
    "    feature_fn=partial(featurize_melspec, hop_length=186),\n",
    "    sr=8000,\n",
    "    subsample_length=1,\n",
    "    id_column='yt_id',\n",
    "    label_column='laughter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 44, 128)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asds[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the audioset model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seeds\n",
    "pl.utilities.seed.seed_everything(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves top-K checkpoints based on \"val_loss\" metric\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    dirpath=\"./pretrained_audioset/\",\n",
    "    filename=\"audioset-{epoch:02d}-{val_loss:.2f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000018vscode-remote?line=0'>1</a>\u001b[0m train_idx, test_idx \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(ShuffleSplit(n_splits\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, test_size\u001b[39m=\u001b[39m\u001b[39m0.15\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m22\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(ds)))))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000018vscode-remote?line=1'>2</a>\u001b[0m train_ds \u001b[39m=\u001b[39m Subset(ds, train_idx)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000018vscode-remote?line=2'>3</a>\u001b[0m test_ds \u001b[39m=\u001b[39m Subset(ds, test_idx)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "train_idx, test_idx = next(iter(ShuffleSplit(n_splits=1, test_size=0.15, random_state=22).split(range(len(ds)))))\n",
    "train_ds = Subset(ds, train_idx)\n",
    "test_ds = Subset(ds, test_idx)\n",
    "fold_outputs = do_fold(train_ds, test_ds, 'resnet',\n",
    "    trainer_params={'callbacks': [checkpoint_callback]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make audios into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from constants import laughter_data_path\n",
    "import audio_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/Jose/gdrive/data/lared_laughter/laughter_data/ml_datasets/tight'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laughter_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 504/504 [00:04<00:00, 102.11it/s]\n"
     ]
    }
   ],
   "source": [
    "audios_path = os.path.join(laughter_data_path, 'audio')\n",
    "all_audioset_files = librosa.util.find_files(audios_path, ext=['wav'])\n",
    "audios = audio_utils.parallel_load_audio_batch(all_audioset_files, n_processes=8, sr=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11278/1205596482.py:2: FutureWarning: Pass orig_sr=44100, target_sr=8000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  audios[i] = librosa.resample(audios[i], 44100, 8000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(audios)):\n",
    "    audios[i] = librosa.resample(audios[i], orig_sr=44100, target_sr=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = {}\n",
    "for i in range(len(all_audioset_files)):\n",
    "    f = all_audioset_files[i]\n",
    "    f = os.path.basename(f)[:-4]\n",
    "    h[f] = audios[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(laughter_data_path, \"lared_audios.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(h, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features for the LaRed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jose.torch.hooks import FeatureRecorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with dropout=0.5\n",
      "training with dropout=0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f4a7f233b20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "model = System.load_from_checkpoint('./pretrained_audioset/audioset-epoch=09-val_loss=0.46.ckpt')\n",
    "recorder = FeatureRecorder()\n",
    "model.model.block4[1].bn2.register_forward_hook(recorder.get_hook('resnet_deepest_conv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = pd.read_csv('../dataset/computational_examples.csv')\n",
    "examples = examples[examples['condition'] == 'av']\n",
    "audios_path = os.path.join(dataset_path, \"lared_audios.pkl\")\n",
    "audios = pickle.load(open(audios_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>person</th>\n",
       "      <th>cam</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>condition</th>\n",
       "      <th>calibration</th>\n",
       "      <th>hash</th>\n",
       "      <th>ini_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>...</th>\n",
       "      <th>gt_offset</th>\n",
       "      <th>gt_laughter</th>\n",
       "      <th>is_laughter</th>\n",
       "      <th>confidence</th>\n",
       "      <th>intensity</th>\n",
       "      <th>attempt</th>\n",
       "      <th>pressed_key</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>rating_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>f4c9842cec7be99eeaaea36d0c7d077c4d5d94596dc731...</td>\n",
       "      <td>av</td>\n",
       "      <td>False</td>\n",
       "      <td>1170917790b51bc5a8dacacc4d8ed8c410b7ea6bb7ea4b...</td>\n",
       "      <td>7360.29</td>\n",
       "      <td>7361.54</td>\n",
       "      <td>...</td>\n",
       "      <td>4.420238</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.792656</td>\n",
       "      <td>3.893757</td>\n",
       "      <td>bf6cd2aeaf7c77c2c2ff873e6f603b7d46cd64c74e9ebd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2715</td>\n",
       "      <td>2715</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>eecc0cf5d634ce45a98cbbda30c922f2a2cfcb1877124c...</td>\n",
       "      <td>av</td>\n",
       "      <td>False</td>\n",
       "      <td>1170917790b51bc5a8dacacc4d8ed8c410b7ea6bb7ea4b...</td>\n",
       "      <td>7360.29</td>\n",
       "      <td>7361.54</td>\n",
       "      <td>...</td>\n",
       "      <td>4.420238</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.692556</td>\n",
       "      <td>4.160691</td>\n",
       "      <td>5e161ddc0b4b35ca47cf769cf612f6d48015bb3b95763e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>4198c11729cea33268040a725998f16478a6564d4af091...</td>\n",
       "      <td>av</td>\n",
       "      <td>False</td>\n",
       "      <td>11bc9d8aca57ab2aef4c5305b080fa49c08665d9e94190...</td>\n",
       "      <td>2216.02</td>\n",
       "      <td>2216.54</td>\n",
       "      <td>...</td>\n",
       "      <td>3.928860</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.859390</td>\n",
       "      <td>4.227424</td>\n",
       "      <td>9a3c519923fbcec61d8195147439f87b23d34e4e777ef5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2430</td>\n",
       "      <td>2430</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>a9760ede24043c59a0151b09a46e866fa43f74bd60b682...</td>\n",
       "      <td>av</td>\n",
       "      <td>False</td>\n",
       "      <td>11bc9d8aca57ab2aef4c5305b080fa49c08665d9e94190...</td>\n",
       "      <td>2216.02</td>\n",
       "      <td>2216.54</td>\n",
       "      <td>...</td>\n",
       "      <td>3.928860</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.759289</td>\n",
       "      <td>3.493357</td>\n",
       "      <td>f82d2bc978d5b249847debaa987922931259c56f12b1af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>f4c9842cec7be99eeaaea36d0c7d077c4d5d94596dc731...</td>\n",
       "      <td>av</td>\n",
       "      <td>False</td>\n",
       "      <td>c1d181e74dbdbce1e51d7d0bfd6e036913896dd1f22856...</td>\n",
       "      <td>3346.30</td>\n",
       "      <td>3347.70</td>\n",
       "      <td>...</td>\n",
       "      <td>3.255518</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.158689</td>\n",
       "      <td>3.193057</td>\n",
       "      <td>955ec127e6f86edf3dbb800ad217e18b1f1ec380090a4b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0  person  cam  \\\n",
       "4           1058        1058      25    1   \n",
       "5           2715        2715      25    1   \n",
       "10           582         582      35    3   \n",
       "11          2430        2430      35    3   \n",
       "16          1001        1001       1    4   \n",
       "\n",
       "                                               hit_id condition  calibration  \\\n",
       "4   f4c9842cec7be99eeaaea36d0c7d077c4d5d94596dc731...        av        False   \n",
       "5   eecc0cf5d634ce45a98cbbda30c922f2a2cfcb1877124c...        av        False   \n",
       "10  4198c11729cea33268040a725998f16478a6564d4af091...        av        False   \n",
       "11  a9760ede24043c59a0151b09a46e866fa43f74bd60b682...        av        False   \n",
       "16  f4c9842cec7be99eeaaea36d0c7d077c4d5d94596dc731...        av        False   \n",
       "\n",
       "                                                 hash  ini_time  end_time  \\\n",
       "4   1170917790b51bc5a8dacacc4d8ed8c410b7ea6bb7ea4b...   7360.29   7361.54   \n",
       "5   1170917790b51bc5a8dacacc4d8ed8c410b7ea6bb7ea4b...   7360.29   7361.54   \n",
       "10  11bc9d8aca57ab2aef4c5305b080fa49c08665d9e94190...   2216.02   2216.54   \n",
       "11  11bc9d8aca57ab2aef4c5305b080fa49c08665d9e94190...   2216.02   2216.54   \n",
       "16  c1d181e74dbdbce1e51d7d0bfd6e036913896dd1f22856...   3346.30   3347.70   \n",
       "\n",
       "    ...  gt_offset  gt_laughter  is_laughter  confidence  intensity  attempt  \\\n",
       "4   ...   4.420238         True         True           7          7        0   \n",
       "5   ...   4.420238         True         True           4          5        0   \n",
       "10  ...   3.928860         True         True           7          2        0   \n",
       "11  ...   3.928860         True         True           7          3        0   \n",
       "16  ...   3.255518         True         True           7          7        0   \n",
       "\n",
       "    pressed_key     onset    offset  \\\n",
       "4          True  2.792656  3.893757   \n",
       "5          True  2.692556  4.160691   \n",
       "10         True  2.859390  4.227424   \n",
       "11         True  2.759289  3.493357   \n",
       "16         True  2.158689  3.193057   \n",
       "\n",
       "                                          rating_hash  \n",
       "4   bf6cd2aeaf7c77c2c2ff873e6f603b7d46cd64c74e9ebd...  \n",
       "5   5e161ddc0b4b35ca47cf769cf612f6d48015bb3b95763e...  \n",
       "10  9a3c519923fbcec61d8195147439f87b23d34e4e777ef5...  \n",
       "11  f82d2bc978d5b249847debaa987922931259c56f12b1af...  \n",
       "16  955ec127e6f86edf3dbb800ad217e18b1f1ec380090a4b...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: 672, audios: 504, not found: 0\n",
      "df: 672, audios: 504, not found: 0\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "ds = SwitchBoardLaughterDataset(\n",
    "    df=examples,\n",
    "    audios=audios,\n",
    "    feature_fn=partial(featurize_melspec, hop_length=186),\n",
    "    sr=8000,\n",
    "    subsample_length=1.0,\n",
    "    id_column='hash',\n",
    "    label_column='pressed_key')\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        ds, batch_size=100, shuffle=False, num_workers=10,\n",
    "        collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "recorder.clear()\n",
    "for X, y in data_loader_train:\n",
    "    y_hat = model(X)\n",
    "recorder.store_as_dict('./features/resnet_deepest_conv.pkl', dict_keys=examples.hash.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pickle.load(open('./features/resnet_deepest_conv.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['resnet_deepest_conv']['cbc382abda5165dd26a7ca9e05e7ed3000933489864cb9ed1c25fd4da2a25d19'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
