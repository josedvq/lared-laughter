{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from models.models import MLPModel, ResNetBigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from constants import cloud_data_path, audioset_data_path\n",
    "from dataset import SwitchBoardLaughterDataset\n",
    "from audio_utils import featurize_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class System(pl.LightningModule):\n",
    "    def __init__(self, model_name, model_hparams={}, optimizer_name='adam', optimizer_hparams={}):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = {\n",
    "            'mlp': MLPModel(),\n",
    "            'resnet': ResNetBigger(linear_layer_size=64, filter_sizes=[64,32,16,16])\n",
    "        }[model_name]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        X, Y = batch\n",
    "\n",
    "        output = self.model(X).squeeze()\n",
    "        loss = F.binary_cross_entropy_with_logits(output, Y)\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=.001)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, Y = batch\n",
    "\n",
    "        output = self.model(X).squeeze()\n",
    "        val_loss = F.binary_cross_entropy_with_logits(output, Y)\n",
    "        self.log('val_loss', val_loss)\n",
    "\n",
    "        return (output, Y.squeeze())\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        all_outputs = torch.cat([o[0] for o in validation_step_outputs]).cpu()\n",
    "        all_labels = torch.cat([o[1] for o in validation_step_outputs]).cpu()\n",
    "\n",
    "        val_auc = roc_auc_score(all_labels, all_outputs)\n",
    "        self.log('val_auc', val_auc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, Y = batch\n",
    "\n",
    "        output = self.model(X).squeeze()\n",
    "\n",
    "        return (output, Y.squeeze())\n",
    "\n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        all_outputs = torch.cat([o[0] for o in test_step_outputs]).cpu()\n",
    "        all_labels = torch.cat([o[1] for o in test_step_outputs]).cpu()\n",
    "\n",
    "        test_auc = roc_auc_score(all_labels, all_outputs)\n",
    "        self.test_results = {'auc': test_auc, 'proba': all_outputs}\n",
    "        self.log('test_auc', test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fold(train_ds, test_ds, model_name='resnet'):\n",
    "    # data loaders\n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_ds, batch_size=100, shuffle=True, num_workers=10,\n",
    "        collate_fn=None)\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=100, shuffle=False, num_workers=10,\n",
    "        collate_fn=None)\n",
    "\n",
    "    system = System(model_name)\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")],\n",
    "        accelerator='gpu',\n",
    "        log_every_n_steps=1,\n",
    "        max_epochs=-1)\n",
    "    trainer.fit(system, data_loader_train, data_loader_val)\n",
    "\n",
    "    trainer.test(system, data_loader_val)\n",
    "    return system.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(outputs, labels, type='binary'):\n",
    "    if type == 'binary':\n",
    "        proba = torch.sigmoid(outputs)\n",
    "        pred = (proba > 0.5)\n",
    "\n",
    "        correct = pred.eq(outputs.bool()).sum().item()\n",
    "        return {\n",
    "            'auc': roc_auc_score(labels, proba),\n",
    "            'correct': correct\n",
    "        }\n",
    "    elif type == 'regression':\n",
    "        return {\n",
    "            'mse': torch.nn.functional.mse_loss(outputs, labels, reduction='mean'),\n",
    "            'l1': torch.nn.functional.l1_loss(outputs, labels, reduction='mean')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_run(dataset, model_name, metrics_name='binary'):\n",
    "    \n",
    "    seed = 22\n",
    "    cv_splits = KFold(n_splits=2, random_state=seed, shuffle=True).split(range(len(ds)))\n",
    "\n",
    "    outputs = torch.empty((len(ds),))\n",
    "    for f, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        # create datasets    \n",
    "        train_ds = Subset(dataset, train_idx)\n",
    "        test_ds = Subset(dataset, test_idx)\n",
    "\n",
    "        fold_outputs = do_fold(train_ds, test_ds, model_name)\n",
    "        outputs[test_idx] = fold_outputs['proba'].cpu()\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    labels = torch.Tensor(ds.get_all_labels())\n",
    "    run_metrics = get_metrics(outputs, labels, metrics_name)\n",
    "    return outputs, run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loading\n",
    "examples = pd.read_csv('./data/audioset/examples.csv')\n",
    "audios = pickle.load(open(os.path.join(audioset_data_path, 'audioset_audios.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: 19354, audios: 16148, not found: 11024\n"
     ]
    }
   ],
   "source": [
    "ds = SwitchBoardLaughterDataset(\n",
    "    df=examples,\n",
    "    audios=audios,\n",
    "    feature_fn=partial(featurize_mfcc, hop_length=186),\n",
    "    sr=8000,\n",
    "    subsample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kTLa7Gx_WcY',\n",
       " 'F0AtWOUItaQ',\n",
       " 'fFVT_CtL62M',\n",
       " 'LT_Jufs5YAQ',\n",
       " 'Bzr_Akg7WJ0',\n",
       " '10aBef0Ghkc',\n",
       " 'Yd0D6_oC0xU',\n",
       " 'v_y7n20ryX0',\n",
       " 'fVLi5-KnhtY',\n",
       " 'Q6SgmlYMYLA',\n",
       " 'WvZ_wamj6NA',\n",
       " '2j4m7JsNtNA',\n",
       " 'VTOf24hbq0A',\n",
       " 'tESEL6NZcKY',\n",
       " 'hoPnrbKOEl8',\n",
       " '0x82_HySIVU',\n",
       " 'b04gwYJKwsQ',\n",
       " 'EEhnuLFYehU',\n",
       " 'Ml2KMRBE_L4',\n",
       " 'PzS_cNwa4xM',\n",
       " 'QXnJ2manIdI',\n",
       " '0CbBZ-XeZNU',\n",
       " 'LtYJXKeUMXA',\n",
       " '-znnr5EbiAc',\n",
       " 'B9j8-Cf1ZW8',\n",
       " 'Fy51z2RwH3E',\n",
       " 'fCr0jToaMs4',\n",
       " '6uyTDcNWV_s',\n",
       " 'N-fa5t6WnDM',\n",
       " 'PPqooXoOpRs',\n",
       " '5ZqT7KgdYu8',\n",
       " '077aWlQn6XI',\n",
       " 'Pk5NZe-ah4U',\n",
       " '6iNLmtQmy3Y',\n",
       " 'wMfcj8J1aso',\n",
       " '1FbxStVuFYU',\n",
       " 'BAkDiKQEjrY',\n",
       " 'Uf03ZMnxw9c',\n",
       " 'FwGEy5Ek_xw',\n",
       " '-9mHz0OsKKw',\n",
       " 'hMTj17ezEuI',\n",
       " 'lkIpnrLIVVc',\n",
       " 's4_fKHLaaRg',\n",
       " '31c2kosdtuo',\n",
       " 'dBNvrAJqw-I',\n",
       " 'HIn8Gt_bc5Y',\n",
       " 'Z0htOHTOtHY',\n",
       " '4VegMOtu5YU',\n",
       " 'fofP4lar_QY',\n",
       " 'bNhA2IsT9R4',\n",
       " 'QP_ZCssCySw',\n",
       " '92sRFZvCnWo',\n",
       " 'E3F9bzeCgTQ',\n",
       " 'tHIQdXyNxwY',\n",
       " 'QPR_tghZjAI',\n",
       " 'zYM0gtd_PRo',\n",
       " 'DG5d4megH8g',\n",
       " 'yvtRYZ5EasA',\n",
       " 'MuSozMIsi7g',\n",
       " 'JV_IOR3DqiM',\n",
       " 'F3WR_RJ9fDM',\n",
       " 'zE6BVRSQNZU',\n",
       " '22DYoQhJs4o',\n",
       " 'QQo7_R2X8oA',\n",
       " 'YRdL_tPsk6Q',\n",
       " 'IrQRVI8y5j8',\n",
       " 'l5Kj9oMx3iw',\n",
       " 'PXvygAB5RKg',\n",
       " 'Y-En0Z6Iabo',\n",
       " '06pzMwo6VHA',\n",
       " '-l-E3kyNcag',\n",
       " 'GMtb7U-8IYM',\n",
       " '5l-SoHOFw_c',\n",
       " 'FI6SwkcxekM',\n",
       " '_WCpjcXIYzA',\n",
       " 'CBUAy9Zl6ZE',\n",
       " '4EnJ-JGde6o',\n",
       " 'ZUcHBeueBww',\n",
       " 'PSQiUBW7pnk',\n",
       " 'gVDSFrufSJ8',\n",
       " '8AWiBbAtpCY',\n",
       " 'Zy0VM2u3nJI',\n",
       " 'Y9Hls0X21Q8',\n",
       " 'lJGtKgjQNgU',\n",
       " 'LW2d0m3c3Kw',\n",
       " 'AnMR6SOBa9k',\n",
       " '-36qTeAdDMI',\n",
       " 'Cc2sezm2Y6w',\n",
       " 'wHISHmuP58s',\n",
       " '4NZkW-XaIa4',\n",
       " 'PY6W2EGF9ho',\n",
       " 'MfKSVJIcDK0',\n",
       " 'EvBjD-sb1Gk',\n",
       " 'QAdQcwrKlt8',\n",
       " '_qP21HqOmA0',\n",
       " 'x11_NJ3hEVw',\n",
       " 'Wmjm2mu_7fY',\n",
       " 'JC41M7RPSec',\n",
       " 'eA2efaz3RSE',\n",
       " 'GpGKHdqpoLE']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.notfound[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>yt_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>tag_strings</th>\n",
       "      <th>laughter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>--5OkAjCI7g</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>['/m/07sq110', '/m/0ytgt']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>--AQYzDx57k</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>['/m/07rgt08', '/m/09x0r']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>--sIMPsphRI</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>['/m/01j3sz', '/m/05tny_', '/m/068hy', '/m/07r...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1rvxdiILiM</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>['/m/04rlf', '/m/07rgt08']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-3c6pnDzbt8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>['/m/01j3sz', '/m/09x0r']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        yt_id  start_time  end_time  \\\n",
       "0           0  --5OkAjCI7g        40.0      50.0   \n",
       "1           1  --AQYzDx57k         0.0      10.0   \n",
       "2           2  --sIMPsphRI        10.0      20.0   \n",
       "3           3  -1rvxdiILiM        30.0      40.0   \n",
       "4           4  -3c6pnDzbt8         0.0      10.0   \n",
       "\n",
       "                                         tag_strings  laughter  \n",
       "0                         ['/m/07sq110', '/m/0ytgt']      True  \n",
       "1                         ['/m/07rgt08', '/m/09x0r']      True  \n",
       "2  ['/m/01j3sz', '/m/05tny_', '/m/068hy', '/m/07r...      True  \n",
       "3                         ['/m/04rlf', '/m/07rgt08']      True  \n",
       "4                          ['/m/01j3sz', '/m/09x0r']      True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 50.0, 10.032)\n",
      "(4.818022263189084, 1.0, 10.032)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 7.58273574e-02, -8.08831940e+01,  2.76844616e+01, ...,\n",
       "          6.37817919e-01,  4.71592188e-01,  6.44641519e-01],\n",
       "        [ 1.02906934e-01, -8.21656876e+01,  2.29767151e+01, ...,\n",
       "          6.37817919e-01,  4.71592188e-01,  6.44641519e-01],\n",
       "        [ 1.23297036e-01, -8.74584351e+01,  2.98735294e+01, ...,\n",
       "          6.37817919e-01,  4.71592188e-01,  6.44641519e-01],\n",
       "        ...,\n",
       "        [ 1.08495703e-01, -5.68558159e+01,  1.47418499e+01, ...,\n",
       "          3.38231713e-01,  1.76223204e-01, -2.87418544e-01],\n",
       "        [ 1.06348523e-01, -5.46372261e+01,  1.24134502e+01, ...,\n",
       "          3.38231713e-01,  1.76223204e-01, -2.87418544e-01],\n",
       "        [ 9.18559128e-02, -6.25113564e+01,  1.73280182e+01, ...,\n",
       "          3.38231713e-01,  1.76223204e-01, -2.87418544e-01]]),\n",
       " True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with dropout=0.5\n",
      "training with dropout=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | ResNetBigger | 221 K \n",
      "---------------------------------------\n",
      "221 K     Trainable params\n",
      "0         Non-trainable params\n",
      "221 K     Total params\n",
      "0.887     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386fce38e79c4795bcb85f1af89f40e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 50.0, 10.032)\n",
      "(6.923743460370193, 1.0, 10.032)\n",
      "(0, 390.0, 10.031125)\n",
      "(0, 40.0, 10.032)(0.27314181848414243, 1.0, 10.031125)\n",
      "\n",
      "(0, 10.0, 10.032)\n",
      "(0, 90.0, 10.032)(8.678272183076839, 1.0, 10.032)(2.9256491713961794, 1.0, 10.032)\n",
      "(0, 10.0, 10.032)(0, 20.0, 10.032)\n",
      "\n",
      "\n",
      "\n",
      "(4.5808858874405445, 1.0, 10.032)(7.3563552022461485, 1.0, 10.032)\n",
      "(5.0293857214034645, 1.0, 10.032)(0, 370.0, 10.032)\n",
      "\n",
      "\n",
      "(0.17019339061911762, 1.0, 10.032)\n",
      "(0, 20.0, 10.032)\n",
      "(0.3031256918567414, 1.0, 10.032)(0, 10.0, 10.032)\n",
      "(0, 440.0, 10.031125)\n",
      "\n",
      "(5.483010701096184, 1.0, 10.032)\n",
      "(3.1476945096945825, 1.0, 10.031125)(0, 120.0, 10.032)(0, 570.0, 10.031125)\n",
      "\n",
      "(0, 430.0, 10.032)\n",
      "(4.008147529413328, 1.0, 10.032)\n",
      "(1.591065236930446, 1.0, 10.031125)(5.9202852383784474, 1.0, 10.032)\n",
      "\n",
      "(0, 10.0, 10.032)\n",
      "\n",
      "(0, 70.0, 10.032)(1.7295632809359318, 1.0, 10.032)\n",
      "(0, 160.0, 10.032)\n",
      "(7.297754850217813, 1.0, 10.032)\n",
      "(0, 50.0, 10.032)(2.9917862983565633, 1.0, 10.032)\n",
      "(0, 30.0, 10.032)\n",
      "\n",
      "(8.220980023752713, 1.0, 10.032)\n",
      "\n",
      "(5.17430382171779, 1.0, 10.032)(0, 90.0, 10.032)\n",
      "\n",
      "(0.38739967464986536, 1.0, 10.032)\n",
      "(0, 40.0, 10.032)\n",
      "(0, 50.0, 10.032)(4.523435242791391, 1.0, 10.032)(0, 340.0, 10.032)\n",
      "\n",
      "(1.3692366829299492, 1.0, 10.032)\n",
      "\n",
      "(8.502287003166177, 1.0, 10.032)\n",
      "(0, 50.0, 10.032)(0, 10.0, 10.032)\n",
      "\n",
      "(0, 16.0, 9.769875)(8.71567158293328, 1.0, 10.032)\n",
      "(5.657846310648586, 1.0, 10.032)(0, 420.0, 10.032)(0, 110.0, 10.032)\n",
      "(1.7574076158848426, 1.0, 9.769875)\n",
      "\n",
      "\n",
      "\n",
      "(5.7832969543508685, 1.0, 10.032)(7.22692396738359, 1.0, 10.032)\n",
      "\n",
      "(0, 240.0, 10.031125)\n",
      "(2.308673296669256, 1.0, 10.031125)(0, 30.0, 10.032)(0, 40.0, 10.032)\n",
      "\n",
      "(0, 10.0, 10.032)(0, 16.0, 9.576)(6.8619867565565915, 1.0, 10.032)\n",
      "\n",
      "\n",
      "\n",
      "(0, 300.0, 10.032)(0, 50.0, 10.032)(4.315982531825509, 1.0, 10.032)(5.685076242619706, 1.0, 9.576)\n",
      "(5.851322994472487, 1.0, 10.032)\n",
      "\n",
      "\n",
      "(8.940150119393188, 1.0, 10.032)\n",
      "(3.203011291661427, 1.0, 10.032)\n",
      "\n",
      "(0, 30.0, 10.032)(0, 270.0, 10.032)(0, 40.0, 10.032)\n",
      "\n",
      "\n",
      "(1.5092411069954008, 1.0, 10.032)(0, 210.0, 10.032)(3.1579345571127893, 1.0, 10.032)(3.281800966599037, 1.0, 10.032)\n",
      "\n",
      "\n",
      "\n",
      "(7.039466574816059, 1.0, 10.032)\n",
      "(0, 30.0, 10.032)(0, 50.0, 10.032)(0, 40.0, 10.032)(0, 260.0, 10.032)\n",
      "\n",
      "\n",
      "\n",
      "(4.5278628323385535, 1.0, 10.032)(2.681313794505011, 1.0, 10.032)(4.242374290301072, 1.0, 10.032)\n",
      "(2.5033403796443334, 1.0, 10.032)\n",
      "\n",
      "\n",
      "(0, 40.0, 10.032)(0, 110.0, 10.032)(0, 20.0, 10.032)"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jose/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/jose/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jose/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 363, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/dataset.py\", line 28, in __getitem__\n    audio_file = self.audios[yt_id]\nKeyError: '-4yy61BH-O8'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m outputs, metrics \u001b[39m=\u001b[39m do_run(ds, \u001b[39m'\u001b[39;49m\u001b[39mresnet\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbinary\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb Cell 7'\u001b[0m in \u001b[0;36mdo_run\u001b[0;34m(dataset, model_name, metrics_name)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000005vscode-remote?line=8'>9</a>\u001b[0m train_ds \u001b[39m=\u001b[39m Subset(dataset, train_idx)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000005vscode-remote?line=9'>10</a>\u001b[0m test_ds \u001b[39m=\u001b[39m Subset(dataset, test_idx)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000005vscode-remote?line=11'>12</a>\u001b[0m fold_outputs \u001b[39m=\u001b[39m do_fold(train_ds, test_ds, model_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000005vscode-remote?line=12'>13</a>\u001b[0m outputs[test_idx] \u001b[39m=\u001b[39m fold_outputs[\u001b[39m'\u001b[39m\u001b[39mproba\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000005vscode-remote?line=13'>14</a>\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb Cell 5'\u001b[0m in \u001b[0;36mdo_fold\u001b[0;34m(train_ds, test_ds, model_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000003vscode-remote?line=9'>10</a>\u001b[0m system \u001b[39m=\u001b[39m System(model_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000003vscode-remote?line=10'>11</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000003vscode-remote?line=11'>12</a>\u001b[0m     callbacks\u001b[39m=\u001b[39m[EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m)],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000003vscode-remote?line=12'>13</a>\u001b[0m     accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000003vscode-remote?line=13'>14</a>\u001b[0m     log_every_n_steps\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000003vscode-remote?line=14'>15</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000003vscode-remote?line=15'>16</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(system, data_loader_train, data_loader_val)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000003vscode-remote?line=17'>18</a>\u001b[0m trainer\u001b[39m.\u001b[39mtest(system, data_loader_val)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/train.ipynb#ch0000003vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m system\u001b[39m.\u001b[39mtest_results\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:768\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=748'>749</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=749'>750</a>\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=750'>751</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=764'>765</a>\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=765'>766</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=766'>767</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=767'>768</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=768'>769</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=769'>770</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:721\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=718'>719</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=719'>720</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=720'>721</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=721'>722</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=722'>723</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:809\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=804'>805</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=805'>806</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=806'>807</a>\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=807'>808</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=808'>809</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=810'>811</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=811'>812</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1234\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1229'>1230</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1231'>1232</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1233'>1234</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1235'>1236</a>\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1236'>1237</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1321\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1318'>1319</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1319'>1320</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1320'>1321</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1343\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1339'>1340</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1341'>1342</a>\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1342'>1343</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1344'>1345</a>\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1345'>1346</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1411\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1408'>1409</a>\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1409'>1410</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1410'>1411</a>\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1412'>1413</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1414'>1415</a>\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=201'>202</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:154\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=151'>152</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=152'>153</a>\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=153'>154</a>\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=155'>156</a>\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=156'>157</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=201'>202</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:111\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=108'>109</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=109'>110</a>\u001b[0m     batch_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mcurrent\u001b[39m.\u001b[39mready\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=110'>111</a>\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(data_fetcher)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=111'>112</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=112'>113</a>\u001b[0m     batch_idx, batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(data_fetcher)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py:184\u001b[0m, in \u001b[0;36mAbstractDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=182'>183</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=183'>184</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetching_function()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py:259\u001b[0m, in \u001b[0;36mDataFetcher.fetching_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=255'>256</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=256'>257</a>\u001b[0m     \u001b[39m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=257'>258</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=258'>259</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_next_batch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader_iter)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=259'>260</a>\u001b[0m         \u001b[39m# consume the batch we just fetched\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=260'>261</a>\u001b[0m         batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatches\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py:273\u001b[0m, in \u001b[0;36mDataFetcher._fetch_next_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=270'>271</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch_next_batch\u001b[39m(\u001b[39mself\u001b[39m, iterator: Iterator) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=271'>272</a>\u001b[0m     start_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_fetch_start()\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=272'>273</a>\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iterator)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=273'>274</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfetched \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=274'>275</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefetch_batches \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_len:\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/fetching.py?line=275'>276</a>\u001b[0m         \u001b[39m# when we don't prefetch but the dataloader is sized, we use the length for `done`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=518'>519</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=519'>520</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=520'>521</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=521'>522</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=523'>524</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=524'>525</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1203\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1200'>1201</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1201'>1202</a>\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1202'>1203</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1229\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1226'>1227</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1227'>1228</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1228'>1229</a>\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1229'>1230</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py:434\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/_utils.py?line=429'>430</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/_utils.py?line=430'>431</a>\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/_utils.py?line=431'>432</a>\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/_utils.py?line=432'>433</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/_utils.py?line=433'>434</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/jose/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/jose/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jose/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jose/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py\", line 363, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/mnt/c/Users/Jose/Documents/furnace/lared-laughter/audio/dataset.py\", line 28, in __getitem__\n    audio_file = self.audios[yt_id]\nKeyError: '-4yy61BH-O8'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 40.0, 10.032)\n",
      "\n",
      "\n",
      "\n",
      "(8.09308159817612, 1.0, 10.032)(4.781996145329628, 1.0, 10.032)(2.788255199422811, 1.0, 10.032)(7.1476008235799, 1.0, 10.032)\n",
      "\n",
      "\n",
      "\n",
      "(0, 14.0, 9.768)\n",
      "(8.550533206177027, 1.0, 9.768)(0, 20.0, 10.032)(0, 160.0, 10.032)\n",
      "\n",
      "\n",
      "(2.1052466514007167, 1.0, 10.032)(5.362076766924785, 1.0, 10.032)\n",
      "\n",
      "(0, 40.0, 10.032)\n",
      "(0, 130.0, 10.032)(0, 100.0, 10.032)(5.599421946975155, 1.0, 10.032)\n",
      "\n",
      "\n",
      "(4.727751378718121, 1.0, 10.032)(8.12805523203163, 1.0, 10.032)\n",
      "\n",
      "(0, 40.0, 10.032)(0, 130.0, 10.032)\n",
      "\n",
      "(7.600314426966291, 1.0, 10.032)(0.8046210800920879, 1.0, 10.032)\n",
      "\n",
      "(0, 100.0, 10.032)\n",
      "(5.8705746617074945, 1.0, 10.032)(0, 80.0, 10.032)\n",
      "\n",
      "(0.8863354382302091, 1.0, 10.032)\n",
      "(0, 31.0, 9.216)\n",
      "(4.241661947126872, 1.0, 9.216)(0, 25.0, 9.024)\n",
      "\n",
      "(1.9655380239713296, 1.0, 9.024)\n",
      "(0, 10.0, 10.032)\n",
      "(0, 390.0, 10.032)(4.6064981031817585, 1.0, 10.032)\n",
      "\n",
      "(8.87871830532263, 1.0, 10.032)\n",
      "(0, 40.0, 10.032)\n",
      "(6.2413270784531205, 1.0, 10.032)\n",
      "(0, 440.0, 10.032)\n",
      "(5.789322419679352, 1.0, 10.032)\n",
      "(0, 10.0, 10.032)\n",
      "(5.81265244372226, 1.0, 10.032)\n"
     ]
    }
   ],
   "source": [
    "outputs, metrics = do_run(ds, 'resnet', 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8161846056582899, 'correct': 308}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | MyAlexNet | 180 K \n",
      "------------------------------------\n",
      "180 K     Trainable params\n",
      "0         Non-trainable params\n",
      "180 K     Total params\n",
      "0.724     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf247a7f08b4e0e870bd31ae40ed6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f61c8d47df4fb49e8c3404206e8032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0999e4759947b481161de665d3840a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a901f13f434c909b8e6b3710af27fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cf444be8164e8888ecd0ae8b21bea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455a3fd4371443d691b922078b588a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6718cebe564fff8d24cc7932fa47d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6485564fbc64017ac39582a11b0d709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319d1ea544c7487db05b07ad5dc554e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121f58f7cbf843ffa6314c89a2e836e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7403b8a30d14d6abc36978598c638ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77a6a5c4f6949e58b12d0c1b2a8b405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f541531fc7cd4dd496e2cd4815498858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3b8ddd262f44adafb737abe5ea20db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f744645471444bcb7312c22623b8446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c10b39c163345f8a310ba9e78cf3ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a05b24ed68d48beac0b98c4937297bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312180000c0b4242a80381d29c8182bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e732e9c4ee6490b9c38541bd47f47c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8733da30474c4dbdd279c49894dacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f670d648457946e48dffbcd550502aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c793c75160f14ccaaa3d5f8d69225a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abc35bb85e9417fa62e35a73c990543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ed4c28cfa74fa8bbaaf106808426a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bef9c366d44faf863755081d87e58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_auc            0.8045634920634921\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "outputs, metrics = do_run(ds, 'alexnet', 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8096451714872768, 'correct': 326}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
