{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import lared.accel.constants.constants as const\n",
    "from lared.constants.laughter_constants import data_path, cloud_data_path\n",
    "from jose.accel.preproc import interpolate\n",
    "from lared_laughter.constants import datasets_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/Jose/gdrive/data/lared_laughter'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloud_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = pathlib.Path(\"/mnt/e/data/lared\")\n",
    "CHALCEDONY_ROOT = DATA_ROOT / \"accel\"\n",
    "MAPPING_FILE    = CHALCEDONY_ROOT / \"mapping.csv\"\n",
    "MASTER_PICKLE_PATH = CHALCEDONY_ROOT / \"master_data.pkl\"\n",
    "VALID_AUDIO_SEGMENTS_PATH = \"./valid_audio_segments.pkl\"\n",
    "\n",
    "accel_ds_path = os.path.join(cloud_data_path, 'accel', 'accel_ds_human.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "balloon_pop_1_video_frame = 23030 # to \n",
    "balloon_pop_1_accel_frame = 45977 + 19/34\n",
    "\n",
    "balloon_pop_2_video_frame = 74844\n",
    "balloon_pop_2_accel_frame = 47706 + 23/28\n",
    "\n",
    "balloon_pop_3_video_frame = 166836.5\n",
    "balloon_pop_3_accel_frame = 50776 + 30.5/32\n",
    "\n",
    "frame_to_accel = interp1d([balloon_pop_1_video_frame, balloon_pop_3_video_frame], [balloon_pop_1_accel_frame, balloon_pop_3_accel_frame], fill_value=\"extrapolate\")\n",
    "video_seconds_to_accel_sample = interp1d([balloon_pop_1_video_frame/29.97, balloon_pop_3_video_frame/29.97], [balloon_pop_1_accel_frame, balloon_pop_3_accel_frame], fill_value=\"extrapolate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the array to map from PID to node ID\n",
    "mapping_arr = np.loadtxt(MAPPING_FILE, delimiter=',',dtype=int)\n",
    "keys = mapping_arr[:,1]\n",
    "vals = mapping_arr[:,0]\n",
    "mapping = dict(zip(keys,vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the accel stuff\n",
    "master_df = pd.read_pickle(str(MASTER_PICKLE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_seg = pickle.load(open(VALID_AUDIO_SEGMENTS_PATH,'rb'))\n",
    "valid_seg = [el[1] for el in valid_seg]\n",
    "pid_to_valid_seg = {el[0]: (video_seconds_to_accel_sample(el[1]/1000).item(), video_seconds_to_accel_sample(el[2]/1000).item()) for el in valid_seg}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting accel per subject\n",
    "Mapping from pid to accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(accel):\n",
    "    f = interp1d(accel[:, 0], accel[:, 1:], axis=0)\n",
    "\n",
    "    if not np.all( np.diff(accel[:,0].squeeze()) >= 0 ):\n",
    "        print('not in order')\n",
    "\n",
    "    x = np.arange(accel[0, 0], accel[-2, 0], 0.05)\n",
    "\n",
    "    try:\n",
    "        fx = f(x)\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    \n",
    "    return np.hstack([x[:,None], fx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 not in mapping\n",
      "16 not in mapping\n",
      "18 not in mapping\n",
      "23 not in mapping\n",
      "26 not in mapping\n",
      "29 not in mapping\n",
      "49 not in mapping\n",
      "52 not in mapping\n",
      "54 not in mapping\n",
      "56 not in mapping\n",
      "57 not in mapping\n",
      "64 not in mapping\n",
      "73 not in mapping\n",
      "76 not in mapping\n",
      "78 not in mapping\n",
      "84 not in mapping\n",
      "91 not in mapping\n",
      "107 not in mapping\n"
     ]
    }
   ],
   "source": [
    "grouped_df = master_df.groupby('Node')\n",
    "subj_accel = dict()\n",
    "subj_accel_interp = {}\n",
    "for name, group in grouped_df:\n",
    "    \n",
    "    if name not in mapping:\n",
    "        print('{:d} not in mapping'.format(name))\n",
    "        continue\n",
    "        \n",
    "    pid = mapping[name]\n",
    "    \n",
    "    if pid not in pid_to_valid_seg:\n",
    "        # print('{:d} not in pid_to_valid_seg'.format(pid))\n",
    "        continue\n",
    "    subj_valid_seg = pid_to_valid_seg[pid]\n",
    "    \n",
    "    if name in const.FAILED_ACCEL:\n",
    "        # print('failed accel for pid {:d}'.format(pid))\n",
    "        continue\n",
    "    \n",
    "    def assert_len(x):\n",
    "        assert len(x) == 20\n",
    "        \n",
    "    frame_nums = group['Frame_No'].to_numpy()\n",
    "    diffs = np.diff(frame_nums)\n",
    "    first_idx = np.argmax(diffs) # find when the sync jump occurs\n",
    "        \n",
    "    group['x'].apply(assert_len)\n",
    "    group['y'].apply(assert_len)\n",
    "    group['z'].apply(assert_len)\n",
    "    \n",
    "    t = np.concatenate([np.arange(t, t+1, 0.05) for t in frame_nums])\n",
    "    x = np.concatenate(group['x'].tolist())\n",
    "    y = np.concatenate(group['y'].tolist())\n",
    "    z = np.concatenate(group['z'].tolist())\n",
    "        \n",
    "    accel = np.hstack([t[:,None],x[:,None],y[:,None],z[:,None]])[(first_idx+1)*20:,:]\n",
    "    accel = accel[(accel[:,0] > subj_valid_seg[0]) & (accel[:,0] < subj_valid_seg[1]), :] # filter out accel out of valid segment\n",
    "    \n",
    "    # Normalization per subject\n",
    "    accel[:,1:] = StandardScaler().fit_transform(accel[:,1:])\n",
    "    \n",
    "    interp_accel = interpolate(accel)\n",
    "    subj_accel[pid] = accel\n",
    "    subj_accel_interp[pid] = interp_accel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting accel for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = pd.read_csv('../annotation/analysis/annotation_results.csv')\n",
    "examples = examples.groupby('hash').agg({\n",
    "    'hash': 'first',\n",
    "    'cam': 'first',\n",
    "    'person': 'first',\n",
    "    'ini_time': 'first',\n",
    "    'end_time': 'first',\n",
    "    '_ini_time': 'first',\n",
    "    '_end_time': 'first',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_ini_time</th>\n",
       "      <th>_end_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002043005fa746f076c845dc38dd1bd97327bde09e17fcb953102c7ff0b277ac</th>\n",
       "      <td>7960.602390</td>\n",
       "      <td>7968.533860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006f74addfc99845bf6c9f80d13d52ccc189341031525530762bb83dd8b713af</th>\n",
       "      <td>8287.730008</td>\n",
       "      <td>8295.177193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0070b1ba6e8de828aea5c6d3b9d1c3662959fb5f032a679cac78e5ca98fcb1ff</th>\n",
       "      <td>1994.302349</td>\n",
       "      <td>2002.112154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00bcb7cfe796c64cf5fa4195248553f4a5937897650cee2e2bc2d80fba782667</th>\n",
       "      <td>3697.597087</td>\n",
       "      <td>3704.536560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0160da1890b3fc4a923586e460bb781ada3bc56ea9908aea299ce3828a629c42</th>\n",
       "      <td>3526.003181</td>\n",
       "      <td>3532.905657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      _ini_time    _end_time\n",
       "hash                                                                        \n",
       "002043005fa746f076c845dc38dd1bd97327bde09e17fcb...  7960.602390  7968.533860\n",
       "006f74addfc99845bf6c9f80d13d52ccc18934103152553...  8287.730008  8295.177193\n",
       "0070b1ba6e8de828aea5c6d3b9d1c3662959fb5f032a679...  1994.302349  2002.112154\n",
       "00bcb7cfe796c64cf5fa4195248553f4a5937897650cee2...  3697.597087  3704.536560\n",
       "0160da1890b3fc4a923586e460bb781ada3bc56ea9908ae...  3526.003181  3532.905657"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[['_ini_time', '_end_time']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_accel(ex, ini_key = '_ini_time', end_key='_end_time', delta=1):\n",
    "    correction = -14 # accel error, obtained from visual check\n",
    "    \n",
    "    cam2_correction = 0\n",
    "    if ex['cam'] == 2:\n",
    "        cam2_correction = 5 # cam 2 is ahead by 0.25s (5 samples @ 20Hz)\n",
    "    \n",
    "    if ex['person'] not in subj_accel_interp:\n",
    "        return None\n",
    "        \n",
    "    my_subj_accel = subj_accel_interp[ex['person']]\n",
    "    \n",
    "    accel_ini = video_seconds_to_accel_sample(ex[ini_key])\n",
    "    accel_fin = video_seconds_to_accel_sample(ex[end_key])\n",
    "\n",
    "    # number of the first accel sample\n",
    "    ini_idx = np.argmax(my_subj_accel[:,0] > accel_ini)\n",
    "    fin_idx = np.argmax(my_subj_accel[:,0] > accel_fin) + delta\n",
    "    if ini_idx == 0:\n",
    "        print('out of bounds. pid={:d}, accel_ini={:.2f}'.format(ex['person'], accel_ini))\n",
    "    \n",
    "    ini_idx += (correction + cam2_correction)\n",
    "    fin_idx += (correction + cam2_correction)\n",
    "\n",
    "    accel = my_subj_accel[ini_idx: fin_idx, 1:]\n",
    "    return accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_accel(ini_key = '_ini_time', end_key='_end_time'):\n",
    "    all_accel = dict()\n",
    "    for index, ex in tqdm(examples.iterrows()):\n",
    "        ex = ex.to_dict()\n",
    "        accel = extract_accel(ex, ini_key, end_key)\n",
    "        if accel is not None:\n",
    "            all_accel[ex['hash']] = accel\n",
    "    return all_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:00, 3074.82it/s]\n"
     ]
    }
   ],
   "source": [
    "accel_long = get_all_accel('_ini_time', '_end_time')\n",
    "pickle.dump(accel_long, open(os.path.join(datasets_path, 'tight', 'accel_long.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:00, 3003.60it/s]\n"
     ]
    }
   ],
   "source": [
    "accel_short = get_all_accel('ini_time', 'end_time')\n",
    "pickle.dump(accel_short, open(os.path.join(datasets_path, 'tight', 'accel_short.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
