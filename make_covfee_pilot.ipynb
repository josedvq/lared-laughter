{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consent_task():\n",
    "    return {\n",
    "        \"name\": \"Consent\",\n",
    "        \"type\": \"InstructionsTask\",\n",
    "        \"prerequisite\": True,\n",
    "        \"content\": {\n",
    "            \"type\": \"link\",\n",
    "            \"url\": \"$$www$$/consent.md\"\n",
    "        },\n",
    "        \"form\": {\n",
    "            \"fields\": [\n",
    "                {\n",
    "                    \"name\": \"consent1\",\n",
    "                    \"label\": \"I have read and understood the study information dated [DD/MM/YYYY], or it has been read to me. I have been able to ask questions about the study and my questions have been answered to my satisfaction.\",\n",
    "                    \"required\": True,\n",
    "                    \"input\": {\n",
    "                        \"inputType\": \"Checkbox.Group\",\n",
    "                        \"options\": [\n",
    "                            {\n",
    "                                \"label\": \"Yes\",\n",
    "                                \"value\": \"yes\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"consent2\",\n",
    "                    \"label\": \"I consent voluntarily to be a participant in this study and understand that I can refuse to answer questions and I can withdraw from the study at any time, without having to give a reason. \",\n",
    "                    \"required\": True,\n",
    "                    \"input\": {\n",
    "                        \"inputType\": \"Checkbox.Group\",\n",
    "                        \"options\": [\n",
    "                            {\n",
    "                                \"label\": \"Yes\",\n",
    "                                \"value\": \"yes\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"consent3\",\n",
    "                    \"label\": \"I understand that taking part in the study involves providing data ratings or annotations which will be recorded but not linked to my identity, along with data about my interaction with the web interface.\",\n",
    "                    \"required\": True,\n",
    "                    \"input\": {\n",
    "                        \"inputType\": \"Checkbox.Group\",\n",
    "                        \"options\": [\n",
    "                            {\n",
    "                                \"label\": \"Yes\",\n",
    "                                \"value\": \"yes\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"consent4\",\n",
    "                    \"label\": \"I understand that information I provide will be used for scientific publications.\",\n",
    "                    \"required\": True,\n",
    "                    \"input\": {\n",
    "                        \"inputType\": \"Checkbox.Group\",\n",
    "                        \"options\": [\n",
    "                            {\n",
    "                                \"label\": \"Yes\",\n",
    "                                \"value\": \"yes\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"consent5\",\n",
    "                    \"label\": \"I understand that personal information collected about me that can identify me, such as [e.g. my name or where I live], will not be asked nor stored.\",\n",
    "                    \"required\": True,\n",
    "                    \"input\": {\n",
    "                        \"inputType\": \"Checkbox.Group\",\n",
    "                        \"options\": [\n",
    "                            {\n",
    "                                \"label\": \"Yes\",\n",
    "                                \"value\": \"yes\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"consent6\",\n",
    "                    \"label\": \"I give permission for the annotations that I provide to be archived in networked storage at Delft University of Technology in anonymized form so it can be used for future research. I understand that data will not be made public but may be shared with researchers under an End User License Agreement (EULA).\",\n",
    "                    \"required\": True,\n",
    "                    \"input\": {\n",
    "                        \"inputType\": \"Checkbox.Group\",\n",
    "                        \"options\": [\n",
    "                            {\n",
    "                                \"label\": \"Yes\",\n",
    "                                \"value\": \"yes\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instructions_task(file, type='video'):\n",
    "    titles = {\n",
    "        'video': 'Video-only instructions',\n",
    "        'audio': 'Audio-only instructions',\n",
    "        'av': 'Audiovisual instructions'\n",
    "    }\n",
    "    return {\n",
    "        \"name\": titles[type],\n",
    "        \"type\": \"InstructionsTask\",\n",
    "        \"prerequisite\": False,\n",
    "        \"content\": {\n",
    "            \"type\": \"link\",\n",
    "            \"url\": f\"$$www$$/{file}\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_tasks(ex, idx, fpath='laughter_examples/av', calibration=False):\n",
    "    return [\n",
    "      {\n",
    "            \"type\": \"Continuous1DTask\",\n",
    "            \"name\": 'Calibration' if calibration else f\"#{idx}: Recognition\",\n",
    "            \"media\": {\n",
    "                \"type\": \"video\",\n",
    "                \"url\": f\"$$www$$/{fpath}/{ex.get_file_id()}.mp4\",\n",
    "                \"fps\": 25\n",
    "            },\n",
    "            \"intensityInput\": {\n",
    "                \"mode\": \"binary\"\n",
    "            },\n",
    "            \"instructions\": \"Find the person indicated with a red rectangle. Play the video and press indicate the ocurrence of laughter by pressing \\\"q\\\".\"\n",
    "      },\n",
    "      {\n",
    "            \"type\": \"QuestionnaireTask\",\n",
    "            \"name\": 'Intensity' if calibration else f\"#{idx}: Rating\",\n",
    "            \"form\": {\n",
    "            \"fields\": [\n",
    "                {\n",
    "                  \"name\": \"intensity\",\n",
    "                  \"label\": \"Laughter intensity: \",\n",
    "                  \"required\": True,\n",
    "                  \"input\": {\n",
    "                    \"inputType\": \"Slider\",\n",
    "                    \"defaultValue\": 50\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"name\": \"confidence\",\n",
    "                  \"label\": \"Annotation confidence: \",\n",
    "                  \"required\": True,\n",
    "                  \"input\": {\n",
    "                    \"inputType\": \"Slider\",\n",
    "                    \"defaultValue\": 50\n",
    "                  }\n",
    "                }\n",
    "            ]\n",
    "            },\n",
    "            \"media\": {\n",
    "                \"type\": \"video\",\n",
    "                \"url\": f\"$$www$$/{fpath}/{ex.get_file_id()}.mp4\",\n",
    "            },\n",
    "            \"instructions\": \"Find the person indicated with a red rectangle. Play the video and pay attention to this person. Give the required ratings on the right.\"\n",
    "      }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('../lared')\n",
    "from dataset.example import VideoExample, AudioExample, FullExample\n",
    "random.seed(22)\n",
    "np.random.seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_path = '/home/jose/drive/data/lared_laughter/pilot2'\n",
    "laughter_examples_df = pd.read_csv(os.path.join(pilot_path, 'laughter_examples', 'examples.csv'), index_col=0)\n",
    "laughter_examples_df = laughter_examples_df[laughter_examples_df['rect'].notnull()]\n",
    "speech_examples_df = pd.read_csv(os.path.join(pilot_path, 'speech_examples', 'examples.csv'), index_col=0)\n",
    "speech_examples_df = speech_examples_df[speech_examples_df['rect'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "laughter_examples = [('laughter', FullExample(**ex[1].to_dict())) for ex in laughter_examples_df.iterrows()]\n",
    "speech_examples = [('speech', FullExample(**ex[1].to_dict())) for ex in speech_examples_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 83)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obvious_examples_ids = [\n",
    "    '64a92aea9395ace7ac9d60eab34911e419fc66610cd76f1e29df4b4fd16f230f',\n",
    "    '0feb2d80d7e192750c723d7f70dd82b61f3e98de2a437542ae48f5408b073973',\n",
    "    '85aac70ec91eb3be1b313b33e0b7828394bbe4e4edc6a956d1e7061dfc8b250e',\n",
    "    '68d229cf19eec82f37580265ea93892117dd5b559b04d22489da3593315f18e7',\n",
    "    'ced6e78fe7940c10fbc9d7c385273e68459ca399ccb668c8123cf5a66fa99819',\n",
    "    'bb6337eea970487ce9cd4ff26ea78c7acc6d5d1a355b7aa50029a3229f115b21'\n",
    "]\n",
    "obvious_examples = [ex[1] for i, ex in enumerate(laughter_examples) if ex[1].get_hash() in obvious_examples_ids]\n",
    "laughter_examples = [ex for i, ex in enumerate(laughter_examples) if ex[1].get_hash() not in obvious_examples_ids]\n",
    "len(obvious_examples), len(laughter_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_examples = random.sample(speech_examples, 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [*laughter_examples, *speech_examples]\n",
    "random.shuffle(examples)\n",
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit(name, s1, s2, s3, calibration_set):\n",
    "\n",
    "    s1_tasks = [t for i, ex in enumerate(s1) for t in get_rating_tasks(ex[1], idx=i+1, fpath=f'{ex[0]}_examples/video')]\n",
    "    s1_tasks = [\n",
    "        *get_rating_tasks(calibration_set[0], idx=0, fpath='laughter_examples/video', calibration=True),\n",
    "        *s1_tasks[:40], \n",
    "        *get_rating_tasks(calibration_set[1], idx=0, fpath='laughter_examples/video', calibration=True), \n",
    "        *s1_tasks[40:]\n",
    "    ]\n",
    "\n",
    "    s2_tasks = [t for i, ex in enumerate(s2) for t in get_rating_tasks(ex[1], idx=i+1, fpath=f'{ex[0]}_examples/aiv')]\n",
    "    s2_tasks = [\n",
    "        *get_rating_tasks(calibration_set[2], idx=0, fpath='laughter_examples/aiv', calibration=True),\n",
    "        *s2_tasks[:40], \n",
    "        *get_rating_tasks(calibration_set[3], idx=0, fpath='laughter_examples/aiv', calibration=True), \n",
    "        *s2_tasks[40:]\n",
    "    ]\n",
    "\n",
    "    s3_tasks = [t for i, ex in enumerate(s3) for t in get_rating_tasks(ex[1], idx=i+1, fpath=f'{ex[0]}_examples/av')]\n",
    "    s3_tasks = [\n",
    "        *get_rating_tasks(calibration_set[4], idx=0, fpath='laughter_examples/av', calibration=True),\n",
    "        *s3_tasks[:40], \n",
    "        *get_rating_tasks(calibration_set[5], idx=0, fpath='laughter_examples/av', calibration=True), \n",
    "        *s3_tasks[40:]\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"id\": name,\n",
    "        \"name\": name,\n",
    "        \"interface\": {\n",
    "            \"type\": \"timeline\",\n",
    "            \"showProgress\": True\n",
    "        },\n",
    "        \"tasks\": [\n",
    "            get_consent_task(),\n",
    "\n",
    "            get_instructions_task('video_instructions.md', 'video'),\n",
    "            *s1_tasks,\n",
    "\n",
    "            get_instructions_task('audio_instructions.md', 'audio'),\n",
    "            *s2_tasks,\n",
    "\n",
    "            get_instructions_task('av_instructions.md', 'av'),\n",
    "            *s3_tasks,\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = examples[0:40]\n",
    "set2 = examples[40:80]\n",
    "set3 = examples[80:]\n",
    "project = {\n",
    "    \"name\": \"Pilot\",\n",
    "    \"id\": \"pilot\",\n",
    "    \"email\": \"example@example.com\",\n",
    "    \"hits\": [\n",
    "        get_hit('HIT1', set1, set2, set3, obvious_examples),\n",
    "        get_hit('HIT2', set2, set3, set1, obvious_examples),\n",
    "        get_hit('HIT3', set3, set1, set2, obvious_examples)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(project, open('pilot.covfee.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}