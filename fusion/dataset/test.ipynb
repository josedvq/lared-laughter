{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler, RandomSampler\n",
    "from sklearn.model_selection import KFold, GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lared_laughter.fusion.dataset import FatherDataset, FatherDatasetSubset, CacheExtractor\n",
    "from lared_laughter.accel.dataset import AccelExtractor\n",
    "from lared_laughter.audio.dataset import AudioLaughterExtractor\n",
    "from lared_laughter.video.dataset import VideoExtractor\n",
    "from lared_laughter.video.dataset.transforms import get_kinetics_val_transform\n",
    "from lared_laughter.constants import annot_exp_path, datasets_path\n",
    "from lared_laughter.utils import get_metrics, load_examples\n",
    "from lared_laughter.audio.models.resnet import get_pretrained_body as get_audio_feature_extractor\n",
    "from lared_laughter.video.models.models import make_slow_pretrained_body as get_video_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = load_examples(os.path.join(annot_exp_path, 'processed', 'examples_without_calibration.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_ini_time</th>\n",
       "      <th>_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>1233.738593</td>\n",
       "      <td>1242.419436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>1233.738593</td>\n",
       "      <td>1242.419436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        _ini_time    _end_time\n",
       "2220  1233.738593  1242.419436\n",
       "3856  1233.738593  1242.419436"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[(examples['hash'] == '72fe462eccb27f971193e5724c64a7c4537f04bc88593f180ef18121a9dfc779') & (examples['condition'] == 'video')][['_ini_time', '_end_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pre-trained model\n",
      "missing keys []\n",
      "unexpected keys ['model.blocks.5.proj.weight', 'model.blocks.5.proj.bias']\n",
      "loaded pre-trained model\n",
      "missing keys []\n",
      "unexpected keys ['bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var', 'bn3.num_batches_tracked', 'linear1.weight', 'linear1.bias', 'linear2.weight', 'linear2.bias']\n"
     ]
    }
   ],
   "source": [
    "accel_ds_path = os.path.join(datasets_path, 'loose', 'accel_long.pkl')\n",
    "videos_path = os.path.join(datasets_path, 'loose', 'video')\n",
    "audios_path = os.path.join(datasets_path, \"loose\", \"lared_audios.pkl\")\n",
    "extractors = {\n",
    "    'accel': AccelExtractor(accel_ds_path, min_len=1.5, max_len=1.5),\n",
    "    'video': CacheExtractor(\n",
    "        model = get_video_feature_extractor().cuda(),\n",
    "        extractor = VideoExtractor(videos_path, transform=get_kinetics_val_transform(8, 256, False)),\n",
    "        cache_path='./video_cache.pkl'\n",
    "    ),\n",
    "    'audio': CacheExtractor(\n",
    "        model = get_audio_feature_extractor().cuda(),\n",
    "        extractor = AudioLaughterExtractor(audios_path, min_len=1.5, max_len=1.5),\n",
    "        cache_path='./audio_cache.pkl'\n",
    "    )\n",
    "}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = batch[0]\n",
    "    return {k: torch.tensor(v) for k,v in batch.items()}\n",
    "\n",
    "ds = FatherDataset(examples, extractors, label_column='intensity', id_column='hash')\n",
    "train_ds = FatherDatasetSubset(ds, range(1,100), eval=False)\n",
    "eval_ds  = FatherDatasetSubset(ds, range(1,100), eval=True)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(22)\n",
    "loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    # This line below!\n",
    "    sampler=BatchSampler(\n",
    "        RandomSampler(train_ds, generator=g), batch_size=5, drop_last=False\n",
    "    ),\n",
    "    num_workers=0,\n",
    "    generator=g,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 1, 58, 41, 56]\n",
      "(torch.Size([5, 3, 30]), torch.Size([5, 16, 9, 16]), torch.Size([5, 2048, 1, 2, 2]))\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "print((batch['accel'].shape, batch['audio'].shape, batch['video'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractors['video'].store()\n",
    "extractors['audio'].store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[5,6,7]]['accel'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractors['video'].store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accel': [array([[-0.04914867, -0.26731655, -0.26731655, ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.67281616,  0.67281616,  0.67281616, ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.6884482 ,  0.9163148 ,  0.46057492, ...,  0.        ,\n",
       "           0.        ,  0.        ]], dtype=float32)],\n",
       " 'label': array([6.]),\n",
       " 'intval': array([[2.41776103, 3.91776103]]),\n",
       " 'index': [2]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractors['accel'].store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ds)):\n",
    "    s = ds.get_train_item(i)\n",
    "    intval = s['intval']\n",
    "    assert intval[0] < intval[1], i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accel': array([[ 0.99963385,  0.6424623 ,  0.6424623 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.12390687, -0.12390687, -0.12390576, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.65230256,  0.6523019 ,  0.44224632, ...,  0.        ,\n",
       "          0.        ,  0.        ]], dtype=float32),\n",
       " 'label': 4.0,\n",
       " 'intval': [6.654659663666233, 7.487534029482958],\n",
       " 'index': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ec84022e240482976063d686d8e9b1d59e0cbf9b46e763f658e8f2d130d15bbe', 1.7983112267356356, 3.2983112267356356), ('08755169b187562233dc5fabd6268a969fa61915c0d14cc70c37a9b4aa3e38e7', 1.6789426242368215, 3.1789426242368215)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accel': [array([[ 1.1782213 ,  1.1782213 ,  1.1782213 , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [-0.12390796, -0.4699086 , -0.4699075 , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [-0.18791772, -0.39797062,  0.02213785, ...,  0.        ,\n",
       "           0.        ,  0.        ]], dtype=float32),\n",
       "  array([[-0.48548397, -0.04999961, -0.04914819, ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.6728177 ,  1.0548579 ,  0.29077598, ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.00483601,  0.2327093 ,  1.1441808 , ...,  0.        ,\n",
       "           0.        ,  0.        ]], dtype=float32)],\n",
       " 'label': array([4., 4.]),\n",
       " 'intval': array([[1.79831123, 3.29831123],\n",
       "        [1.67894262, 3.17894262]]),\n",
       " 'index': [1, 4]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[[1,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data from extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ff63645dd16f55240e07095d3c46f4fac3f89ef16802cfaceca713f6cf38dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
