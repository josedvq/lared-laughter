{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import types\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import clear_output\n",
    "import pytorch_lightning as pl\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lared_laughter.fusion.dataset import FatherDataset, FatherDatasetSubset\n",
    "from lared_laughter.accel.dataset import AccelExtractor\n",
    "from lared_laughter.audio.dataset import AudioLaughterExtractor\n",
    "from lared_laughter.video.dataset import VideoExtractor\n",
    "from lared_laughter.video.dataset.transforms import get_kinetics_val_transform\n",
    "from lared_laughter.constants import annot_exp_path, datasets_path\n",
    "from lared_laughter.utils import load_examples\n",
    "from lared_laughter.fusion.model import FusionModel\n",
    "from lared_laughter.accel.system import System as AccelSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class System(pl.LightningModule):\n",
    "    def __init__(self, modalities, task='classification'):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.model = FusionModel(modalities)\n",
    "        self.loss_fn = {\n",
    "            'classification':F.binary_cross_entropy_with_logits,\n",
    "            'regression': F.l1_loss\n",
    "        }[task]\n",
    "\n",
    "        self.performance_metric = {\n",
    "            'classification': lambda input, target: roc_auc_score(target, input),\n",
    "            'regression': F.l1_loss\n",
    "        }[task]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self.model(batch).squeeze()\n",
    "        loss = self.loss_fn(output, batch['label'].float())\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=.001)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        output = self.model(batch).squeeze()\n",
    "        val_loss = self.loss_fn(output, batch['label'].float())\n",
    "        self.log('val_loss', val_loss)\n",
    "\n",
    "        return (output, batch['label'])\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        all_outputs = torch.cat([o[0] for o in validation_step_outputs]).cpu()\n",
    "        all_labels = torch.cat([o[1] for o in validation_step_outputs]).cpu()\n",
    "\n",
    "        val_metric = self.performance_metric(all_outputs, all_labels)\n",
    "        self.log('val_metric', val_metric)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        output = self.model(batch).squeeze()\n",
    "\n",
    "        return (output, batch['index'], batch['label'])\n",
    "\n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        all_outputs = torch.cat([o[0] for o in test_step_outputs]).cpu()\n",
    "        all_indices = torch.cat([o[1] for o in test_step_outputs]).cpu()\n",
    "        all_labels = torch.cat([o[2] for o in test_step_outputs]).cpu()\n",
    "\n",
    "        test_metric = self.performance_metric(all_outputs, all_labels)\n",
    "        self.test_results = {\n",
    "            'metric': test_metric,\n",
    "            'index': all_indices,\n",
    "            'proba': all_outputs\n",
    "        }\n",
    "        self.log('test_metric', test_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_accel_model(train_dl, task, log_name=None):\n",
    "    system = AccelSystem('resnet', task)\n",
    "    trainer = pl.Trainer(\n",
    "        # callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")],\n",
    "        accelerator='gpu',\n",
    "        log_every_n_steps=1,\n",
    "        max_epochs=-1,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=False,\n",
    "        logger= pl.loggers.TensorBoardLogger(save_dir='logs/', version=log_name),\n",
    "        enable_checkpointing=False)\n",
    "    trainer.fit(system, train_dl)\n",
    "\n",
    "    # freeze params\n",
    "    for param in system.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    return system.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fold(train_ds, test_ds, modalities, trainer_params={}, log_prefix=None, task='classification', deterministic=False):\n",
    "\n",
    "    num_epochs = {\n",
    "        ('audio',): 12,\n",
    "        ('accel',): 3,#40,\n",
    "        ('video',): 17\n",
    "    }\n",
    "\n",
    "    # data loaders\n",
    "    batch_size = 16 if 'video' in modalities else 64\n",
    "    data_loader_train = torch.utils.data.DataLoader(\n",
    "        train_ds, batch_size=batch_size, shuffle=True, num_workers=10,\n",
    "        collate_fn=None)\n",
    "    data_loader_val = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=batch_size, shuffle=False, num_workers=10,\n",
    "        collate_fn=None)\n",
    "\n",
    "    system = System(modalities, task=task)\n",
    "    trainer_fn = partial(pl.Trainer, **trainer_params)\n",
    "    trainer = trainer_fn(\n",
    "        accelerator='gpu',\n",
    "        log_every_n_steps=1,\n",
    "        max_epochs=num_epochs[modalities],\n",
    "        logger= pl.loggers.TensorBoardLogger(\n",
    "            save_dir='logs/', name='', \n",
    "            version=log_prefix+'_fusion' if log_prefix else None),\n",
    "        deterministic=deterministic,\n",
    "        enable_checkpointing=False)\n",
    "        \n",
    "    trainer.fit(system, data_loader_train)\n",
    "\n",
    "    trainer.test(system, data_loader_val)\n",
    "    return system.test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(ds, modalities, random_state, task='classification', log_prefix=None, first_fold=False, deterministic=False):\n",
    "    cv_splits = list(KFold(n_splits=10, random_state=random_state, shuffle=True).split(range(len(ds))))\n",
    "    if first_fold:\n",
    "        # only do first fold\n",
    "        cv_splits = [cv_splits[0]]\n",
    "    else:\n",
    "        # skip the first fold\n",
    "        cv_splits = cv_splits[1:]\n",
    "\n",
    "    all_results = []\n",
    "    for f, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        # create dss    \n",
    "        train_ds = FatherDatasetSubset(ds, train_idx)\n",
    "        test_ds = FatherDatasetSubset(ds, test_idx)\n",
    "\n",
    "        fold_outputs = do_fold(train_ds, test_ds, modalities,\n",
    "            log_prefix=log_prefix+f'fold{f}' if log_prefix else None,\n",
    "            task=task,\n",
    "            deterministic=deterministic)\n",
    "        all_results.append(fold_outputs)\n",
    "        clear_output(wait=False)\n",
    "\n",
    "    outputs = [r['proba'].numpy() for r in all_results]\n",
    "    indices = [r['index'].numpy() for r in all_results]\n",
    "    metrics = [r['metric'] for r in all_results]\n",
    "    return metrics, outputs, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(regression=False):\n",
    "    examples = load_examples(os.path.join(annot_exp_path, 'processed', 'examples_without_calibration.csv'))\n",
    "    if regression:\n",
    "        examples.loc[examples['intensity'].isna(), 'intensity'] = 0\n",
    "        examples.loc[~examples['pressed_key'], 'intensity'] = 0\n",
    "        label_column = 'intensity'\n",
    "    else:\n",
    "        label_column = 'pressed_key'\n",
    "\n",
    "    res = {}\n",
    "    for input_modalities in [('accel',)]:\n",
    "        input_modality_res = {}\n",
    "\n",
    "        for label_modality in ['audio', 'video', 'av']:\n",
    "\n",
    "            filtered_examples = examples[examples['condition'] == label_modality].reset_index()\n",
    "\n",
    "            print(f'Using {len(filtered_examples)} examples')\n",
    "\n",
    "            # create the feature datasets\n",
    "            extractors = {}\n",
    "            if 'audio' in input_modalities:\n",
    "                audios_path = os.path.join(datasets_path, \"loose\", \"lared_audios.pkl\")\n",
    "                extractors['audio'] = {\n",
    "                    'extractor': AudioLaughterExtractor(audios_path, min_len=1.5, max_len=1.5), \n",
    "                    'id_column': 'hash'\n",
    "                }\n",
    "            if 'video' in input_modalities:\n",
    "                videos_path = '/home/jose/data/lared_video/video'\n",
    "                extractors['video'] = {\n",
    "                    'extractor': VideoExtractor(videos_path,\n",
    "                        transform=get_kinetics_val_transform(8, 256, False)), \n",
    "                    'id_column': 'hash'\n",
    "                }\n",
    "            if 'accel' in input_modalities:\n",
    "                accel_ds_path = os.path.join(datasets_path, 'loose', 'accel_long.pkl')\n",
    "                extractors['accel'] = {\n",
    "                    'extractor': AccelExtractor(accel_ds_path, min_len=1.5, max_len=1.5), \n",
    "                    'id_column': 'hash'\n",
    "                }\n",
    "            ds = FatherDataset(filtered_examples, extractors, label_column=label_column, id_column='hash', )\n",
    "            assert len(ds) == 1318\n",
    "            input_modality_res[label_modality] = []\n",
    "            for i in range(1):\n",
    "                \n",
    "                seed = 22+i\n",
    "                pl.utilities.seed.seed_everything(seed, workers=True)\n",
    "\n",
    "                metrics, probas, indices = do_cross_validation(ds,\n",
    "                    first_fold=False,\n",
    "                    modalities=input_modalities,\n",
    "                    task='regression' if regression else 'classification',\n",
    "                    deterministic=True,\n",
    "                    random_state=seed,\n",
    "                    log_prefix=f'({\"-\".join(input_modalities)})L({label_modality})_run{i}')\n",
    "\n",
    "                input_modality_res[label_modality].append({\n",
    "                    'metrics': metrics,\n",
    "                    'probas': probas,\n",
    "                    'indices': indices,\n",
    "                    'seed': seed\n",
    "                })\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        res['-'.join(input_modalities)] = input_modality_res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "res = get_table(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(res):\n",
    "\n",
    "    input_mod_map = {\n",
    "        'accel': 'Acceleration',\n",
    "        'video': 'Video',\n",
    "        'audio': 'Audio',\n",
    "    }\n",
    "\n",
    "    label_mod_map = {\n",
    "        'video': 'Video',\n",
    "        'audio': 'Audio',\n",
    "        'av': 'Audiovisual'\n",
    "    }\n",
    "\n",
    "    t = []\n",
    "    for input_mod, input_res in res.items():\n",
    "        index = pd.MultiIndex.from_tuples(\n",
    "            [('', 'Input')] +\n",
    "            [('Label Modality', l) for l in ['Audio', 'Video', 'AV']], names=[\"first\", \"second\"])\n",
    "\n",
    "        row = pd.Series(index=index)\n",
    "\n",
    "        row[('', 'Input')] = input_mod_map[input_mod]\n",
    "        for label_mod, label_res in input_res.items():\n",
    "            metrics = np.concatenate([r['metrics'] for r in label_res])\n",
    "            row[('Label Modality', label_mod_map[label_mod])] = f'{np.mean(metrics):.3f} ({np.std(metrics):.3f})'\n",
    "\n",
    "        \n",
    "        t.append(row)\n",
    "    return pd.DataFrame(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrl}\n",
      "\\toprule\n",
      "             & \\multicolumn{4}{l}{Label Modality} \\\\\n",
      "       Input &          Audio &         Video &  AV &   Audiovisual \\\\\n",
      "\\midrule\n",
      "Acceleration &  0.720 (0.042) & 0.697 (0.038) & NaN & 0.692 (0.042) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14710/4221597527.py:21: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  row = pd.Series(index=index)\n",
      "/tmp/ipykernel_14710/3541248050.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(make_table(res).to_latex(\n"
     ]
    }
   ],
   "source": [
    "print(make_table(res).to_latex(\n",
    "    index=False,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ff63645dd16f55240e07095d3c46f4fac3f89ef16802cfaceca713f6cf38dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
