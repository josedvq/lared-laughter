{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "import pickle\n",
    "from hashlib import sha256\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../lared')\n",
    "from helpers import file_functions\n",
    "from dataset.example import VideoExample, AudioExample, FullExample\n",
    "from constants.laughter_constants import data_path, cloud_data_path\n",
    "from data_loading.utils import get_video_caps, AudioFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "get_video_caps() takes 0 positional arguments but 1 was given",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1b491c111364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVideoExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_video_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/hdd/data/lared/concat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_video_caps() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "VideoExample.init_caps(get_video_caps('/mnt/hdd/data/lared/concat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "laughter_ann_path = os.path.join(cloud_data_path, 'laughter.txt')\n",
    "camera_ann_path = os.path.join(cloud_data_path, 'camera.txt')\n",
    "out_path = os.path.join(cloud_data_path, 'examples')\n",
    "images_path = os.path.join(out_path, 'images')\n",
    "\n",
    "\n",
    "laughter_ann = pd.read_csv(laughter_ann_path, sep='\\t',names=['name','participant','ini','fin','dur','type'],header=None)\n",
    "camera_ann = pd.read_csv(camera_ann_path, sep='\\t',names=['name','participant','ini','fin','dur','camera'],header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       name  participant       ini       fin     dur  camera\n",
       "0  camera30         32.0     0.000    10.000  10.000       0\n",
       "1   camera3          3.0   866.280   882.440  16.160       1\n",
       "2   camera3          3.0   883.150   884.490   1.340      12\n",
       "3   camera3          3.0   884.600   888.860   4.260     123\n",
       "4   camera3          3.0  4300.139  4300.956   0.817       4"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>participant</th>\n      <th>ini</th>\n      <th>fin</th>\n      <th>dur</th>\n      <th>camera</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>camera30</td>\n      <td>32.0</td>\n      <td>0.000</td>\n      <td>10.000</td>\n      <td>10.000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>camera3</td>\n      <td>3.0</td>\n      <td>866.280</td>\n      <td>882.440</td>\n      <td>16.160</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>camera3</td>\n      <td>3.0</td>\n      <td>883.150</td>\n      <td>884.490</td>\n      <td>1.340</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>camera3</td>\n      <td>3.0</td>\n      <td>884.600</td>\n      <td>888.860</td>\n      <td>4.260</td>\n      <td>123</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>camera3</td>\n      <td>3.0</td>\n      <td>4300.139</td>\n      <td>4300.956</td>\n      <td>0.817</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "camera_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_camera_by_participant = camera_ann.groupby('participant')\n",
    "df_laughter_by_participant = laughter_ann.groupby('participant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_camera = []\n",
    "for i in df_camera_by_participant.groups:\n",
    "    dfs_camera.append(df_camera_by_participant.get_group(i))\n",
    "dfs_laughter = []\n",
    "for i in df_laughter_by_participant.groups:\n",
    "    dfs_laughter.append(df_laughter_by_participant.get_group(i))\n",
    "participant_ids = df_camera_by_participant.groups.keys()\n",
    "participant_ids = [int(id) for id in participant_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera(camerastr):\n",
    "    if int(camerastr) == 0:\n",
    "        return []\n",
    "    \n",
    "    return [int(c) for c in str(camerastr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the camera where a person is seen\n",
    "def find_cameras(cam, t):\n",
    "    previous = cam[cam['fin'] < t]\n",
    "    if len(previous) == 0:\n",
    "        return []\n",
    "    \n",
    "    row = previous.iloc[-1]\n",
    "    cameras = row.tail()['camera']\n",
    "    return get_camera(cameras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laughter examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'FullExample' object has no attribute 'write_full_first_image'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d8cf216d4325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             })\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhashid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_full_first_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'FullExample' object has no attribute 'write_full_first_image'"
     ]
    }
   ],
   "source": [
    "# Create examples and first images\n",
    "examples = dict()\n",
    "for pid, df_laughter, df_camera in zip(participant_ids, dfs_laughter, dfs_camera):\n",
    "    for index,row in df_laughter.iterrows():\n",
    "        cameras = find_cameras(df_camera, row['ini'])\n",
    "        ini_time = (row['ini'])\n",
    "        fin_time = (row['fin'])\n",
    "\n",
    "        for cam in cameras:\n",
    "\n",
    "            hashstr = '_'.join([str(pid), str(cam), str(ini_time), str(fin_time)])\n",
    "            hashid = sha256(hashstr.encode()).hexdigest()\n",
    "            \n",
    "            examples[hashid] = FullExample({\n",
    "                'id': hashid,\n",
    "                'pid': pid,\n",
    "                'cam': cam,\n",
    "                'ini_time': ini_time,\n",
    "                'fin_time': fin_time\n",
    "            })\n",
    "\n",
    "            examples[hashid].write_full_first_image(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_segments(df_camera, pid, segment_len=10):\n",
    "    examples = list()\n",
    "    it = df_camera.iterrows()\n",
    "    prev = next(it)[1]\n",
    "    for index, row in it:\n",
    "        ini = prev.loc['fin'] + 10\n",
    "        fin = row.loc['ini'] - 10\n",
    "        cameras = get_camera(prev.loc['camera'])\n",
    "\n",
    "        for cam in cameras:\n",
    "            t = ini\n",
    "            while t < fin:\n",
    "                if t < 14*60:\n",
    "                    t += segment_len\n",
    "                    continue\n",
    "\n",
    "                hashstr = '_'.join([str(pid), str(cam), str(t), str(t+segment_len)])\n",
    "                hashid = sha256(hashstr.encode()).hexdigest()\n",
    "                examples.append(FullExample({\n",
    "                    'id': hashid,\n",
    "                    'pid': pid,\n",
    "                    'cam': cam,\n",
    "                    'ini_time': t,\n",
    "                    'fin_time': t + segment_len\n",
    "                }))\n",
    "                t += segment_len\n",
    "        prev = row\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_examples = [create_random_segments(df, pid) for pid, df in zip(participant_ids, dfs_camera)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_examples = [ex for e in random_examples for ex in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample examples and put them in order of pid (for easy labeling)\n",
    "random.seed(22)\n",
    "chosen_examples = random.sample(random_examples, 2000)\n",
    "chosen_examples = sorted(chosen_examples, key=lambda ex: ex.pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "len(chosen_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-04b356135b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchosen_examples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_full_first_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/furnace/lared/dataset/example.py\u001b[0m in \u001b[0;36mwrite_full_first_image\u001b[0;34m(self, fout_path)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_video_ini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ex in tqdm(chosen_examples[:2000]):\n",
    "    ex.write_full_first_image(images_path)"
   ]
  },
  {
   "source": [
    "# Read CVAT annotations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_dict = {ex.id: ex for ex in random_examples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvat_bb_path = os.path.join(cloud_data_path, 'examples/pilot/cvat.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the BBs from cvat annotations\n",
    "# Read camera and bounding box from it\n",
    "with open(cvat_bb_path) as json_file:\n",
    "    bbs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of img_id -> img\n",
    "imgs_dict = dict()\n",
    "for img in bbs['images']:\n",
    "    imgs_dict[img['id']] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Unknown format code 'd' for object of type 'str'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-d9c6e7830cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_audiovisual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/furnace/lared/dataset/example.py\u001b[0m in \u001b[0;36mwrite_video\u001b[0;34m(self, fout_path, enlarge_perc)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfout_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONSTANTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_examples_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menlarge_perc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mfout_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{self.get_file_id():s}.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mds_video_cap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_caps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/furnace/lared/dataset/example.py\u001b[0m in \u001b[0;36mget_file_id\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_file_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.pid:d}_{self.id:d}_cam_{self.cam:d}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVideoExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown format code 'd' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "# iterate over annotations\n",
    "for annot in bbs['annotations']:\n",
    "    annot_img = imgs_dict[annot['image_id']]\n",
    "    example_id = annot_img['file_name'].split('_')[1]\n",
    "    example = examples_dict[example_id]\n",
    "\n",
    "    bbox = annot['bbox']\n",
    "    example.rect = [int(e) for e in bbox]\n",
    "\n",
    "    example.write_video()\n",
    "    example.write_audio()\n",
    "    example.write_audiovisual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}